{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_DEEP LEARNING PROGRAMS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsyIOmceSrsHAkWkwPo4Zu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ENG19CS0334-TEJAAL-M/DL_Assignment/blob/main/lab_DEEP_LEARNING_PROGRAMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IGNsyNYGGz9"
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical \n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=1))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(X,y, epochs=100)\n",
        "X_marks=[[20]]\n",
        "print(model.predict(X_marks))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoGoz-iPSHlI",
        "outputId": "ca2b3fc2-707a-456e-f32c-23a0e1f12ae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "x = [[4],[5],[6],[7],[8],[9],[10]]\n",
        "y = [8, 10 , 12, 14, 16, 18, 20]\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, input_dim=1, activation= \"relu\"))\n",
        "model.add(Dense(1000, activation= \"relu\"))\n",
        "model.add(Dense(50, activation= \"relu\"))\n",
        "model.add(Dense(1))\n",
        "#model.summary() \n",
        "#Print model Summarymodel.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.fit(x,y,epochs=200)\n",
        "x=[[12.0]]\n",
        "print(model.predict(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 202.1974 - mean_squared_error: 202.1974\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 159.0827 - mean_squared_error: 159.0827\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 121.1263 - mean_squared_error: 121.1263\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 86.6697 - mean_squared_error: 86.6697\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 55.3303 - mean_squared_error: 55.3303\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 28.4312 - mean_squared_error: 28.4312\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.8892 - mean_squared_error: 8.8892\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2110 - mean_squared_error: 0.2110\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.2620 - mean_squared_error: 4.2620\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 16.9093 - mean_squared_error: 16.9093\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 27.8456 - mean_squared_error: 27.8456\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 30.4326 - mean_squared_error: 30.4326\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 25.4489 - mean_squared_error: 25.4489\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 16.9222 - mean_squared_error: 16.9222\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.6102 - mean_squared_error: 8.6102\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8243 - mean_squared_error: 2.8243\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2273 - mean_squared_error: 0.2273\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3611 - mean_squared_error: 0.3611\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.1939 - mean_squared_error: 2.1939\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.6188 - mean_squared_error: 4.6188\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.7570 - mean_squared_error: 6.7570\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.0823 - mean_squared_error: 8.0823\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 8.4077 - mean_squared_error: 8.4077\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.7774 - mean_squared_error: 7.7774\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.4100 - mean_squared_error: 6.4100\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.6248 - mean_squared_error: 4.6248\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.7882 - mean_squared_error: 2.7882\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2506 - mean_squared_error: 1.2506\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.2812 - mean_squared_error: 0.2812\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0060 - mean_squared_error: 0.0060\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.3530 - mean_squared_error: 0.3530\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0746 - mean_squared_error: 1.0746\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.8264 - mean_squared_error: 1.8264\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.2991 - mean_squared_error: 2.2991\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3318 - mean_squared_error: 2.3318\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9522 - mean_squared_error: 1.9522\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.3313 - mean_squared_error: 1.3313\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6926 - mean_squared_error: 0.6926\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2221 - mean_squared_error: 0.2221\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0129 - mean_squared_error: 0.0129\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0562 - mean_squared_error: 0.0562\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2670 - mean_squared_error: 0.2670\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5277 - mean_squared_error: 0.5277\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7314 - mean_squared_error: 0.7314\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8121 - mean_squared_error: 0.8121\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7542 - mean_squared_error: 0.7542\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5877 - mean_squared_error: 0.5877\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3710 - mean_squared_error: 0.3710\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1705 - mean_squared_error: 0.1705\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0395 - mean_squared_error: 0.0395\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0499 - mean_squared_error: 0.0499\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1443 - mean_squared_error: 0.1443\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2369 - mean_squared_error: 0.2369\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2872 - mean_squared_error: 0.2872\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2777 - mean_squared_error: 0.2777\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2170 - mean_squared_error: 0.2170\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1324 - mean_squared_error: 0.1324\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0558 - mean_squared_error: 0.0558\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0104 - mean_squared_error: 0.0104\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0279 - mean_squared_error: 0.0279\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0652 - mean_squared_error: 0.0652\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0968 - mean_squared_error: 0.0968\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1095 - mean_squared_error: 0.1095\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0999 - mean_squared_error: 0.0999\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0734 - mean_squared_error: 0.0734\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0412 - mean_squared_error: 0.0412\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0150 - mean_squared_error: 0.0150\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0050 - mean_squared_error: 0.0050\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0325 - mean_squared_error: 0.0325\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0419 - mean_squared_error: 0.0419\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0419 - mean_squared_error: 0.0419\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0333 - mean_squared_error: 0.0333\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0205 - mean_squared_error: 0.0205\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0089 - mean_squared_error: 0.0089\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0025 - mean_squared_error: 0.0025\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0072 - mean_squared_error: 0.0072\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0132 - mean_squared_error: 0.0132\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0177 - mean_squared_error: 0.0177\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0145 - mean_squared_error: 0.0145\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0094 - mean_squared_error: 0.0094\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0046 - mean_squared_error: 0.0046\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - mean_squared_error: 0.0065\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0081 - mean_squared_error: 0.0081\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0080 - mean_squared_error: 0.0080\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0064 - mean_squared_error: 0.0064\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0042 - mean_squared_error: 0.0042\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0018 - mean_squared_error: 0.0018\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.9704e-04 - mean_squared_error: 9.9704e-04\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.9017e-04 - mean_squared_error: 9.9017e-04\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.8353e-04 - mean_squared_error: 9.8353e-04\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.7707e-04 - mean_squared_error: 9.7707e-04\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.7078e-04 - mean_squared_error: 9.7078e-04\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6450e-04 - mean_squared_error: 9.6450e-04\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.5802e-04 - mean_squared_error: 9.5802e-04\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.5148e-04 - mean_squared_error: 9.5148e-04\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.4503e-04 - mean_squared_error: 9.4503e-04\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.3859e-04 - mean_squared_error: 9.3859e-04\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.3230e-04 - mean_squared_error: 9.3230e-04\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.2608e-04 - mean_squared_error: 9.2608e-04\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.1993e-04 - mean_squared_error: 9.1993e-04\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.1368e-04 - mean_squared_error: 9.1368e-04\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 9.0741e-04 - mean_squared_error: 9.0741e-04\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0112e-04 - mean_squared_error: 9.0112e-04\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.9498e-04 - mean_squared_error: 8.9498e-04\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.8881e-04 - mean_squared_error: 8.8881e-04\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.8274e-04 - mean_squared_error: 8.8274e-04\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.7665e-04 - mean_squared_error: 8.7665e-04\n",
            "[[23.937544]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diUrefaaSdE-"
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from keras.utils import to_categorical \n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=1))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(X,y, epochs=100)\n",
        "X_marks=[[20]]\n",
        "print(model.predict(X_marks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONW4-aDpdw0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2f4e6e-f951-4f86-f320-bca8f9ffdac8"
      },
      "source": [
        "#01/09/21\n",
        "#Linear regression with model accuracy\n",
        "#import modules\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "X=[[1.0],[2.0],[3],[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[2,4,6,8,10,12, 14, 16,18, 22]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.5, random_state=7)\n",
        "print(\"Training Features\", X_train);\n",
        "print(\"Training Labels\",y_train);\n",
        "print(\"Testing Data\",X_test);\n",
        "print(\"Testing Data\",y_test)\n",
        "reg=linear_model.LinearRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "#accuracy on test set\n",
        "result = reg.score(X_test, y_test)\n",
        "print(\"Accuracy - test set: %.2f%%\" % (result*100.0))\n",
        "X_height=[[12.0]]\n",
        "print(reg.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features [[10.0], [8.0], [4.0], [7.0], [5.0]]\n",
            "Training Labels [22, 16, 8, 14, 10]\n",
            "Testing Data [[9.0], [6.0], [1.0], [3], [2.0]]\n",
            "Testing Data [18, 12, 2, 6, 4]\n",
            "Accuracy - test set: 97.71%\n",
            "[19.01754386 12.1754386   0.77192982  5.33333333  3.05263158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyQSozPjlWKS",
        "outputId": "c0c35c99-99df-4de2-b4be-df267885ec49"
      },
      "source": [
        "#same program as before with more accuracy\n",
        "#import modules\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "X=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "y=[  8, 10 , 12, 14, 16, 18, 20]\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "print(\"Training Features\", X_train);print(\"Training Labels\",y_train);print(\"Training Data\",X_test);print(\"Testing Data\",y_test)\n",
        "reg=linear_model.LinearRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "#accuracy on test set\n",
        "result = reg.score(X_test, y_test)\n",
        "print(\"Accuracy - test set: %.2f%%\" % (result*100.0))\n",
        "X_height=[[12.0]]\n",
        "print(reg.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features [[10.0], [7.0], [5.0], [8.0]]\n",
            "Training Labels [20, 14, 10, 16]\n",
            "Training Data [[6.0], [9.0], [4.0]]\n",
            "Testing Data [12, 18, 8]\n",
            "Accuracy - test set: 100.00%\n",
            "[12. 18.  8.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9mXgFzgSnu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c61f72c-2d7f-41e8-c9f6-d878eb0db3ec"
      },
      "source": [
        "#naive based algorithm\n",
        "#06/09/21\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv(\"Naive-Bayes-Classifier-Data.csv\")\n",
        "print(df)\n",
        "df.head()\n",
        "x=df.drop('diabetes',axis=1)\n",
        "y=df['diabetes']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "model=GaussianNB()\n",
        "model.fit(x_train,y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     glucose  bloodpressure  diabetes\n",
            "0         40             85         0\n",
            "1         40             92         0\n",
            "2         45             63         1\n",
            "3         45             80         0\n",
            "4         40             73         1\n",
            "..       ...            ...       ...\n",
            "990       45             87         0\n",
            "991       40             83         0\n",
            "992       40             83         0\n",
            "993       40             60         1\n",
            "994       45             82         0\n",
            "\n",
            "[995 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SVJIY5DfF5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393f1cfe-63b9-4678-f4d3-8e12b159f71e"
      },
      "source": [
        "#linear regression and logisitc regression difference in ml and  dl\n",
        "#ml logistic regression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X,y)\n",
        "X_marks=[[20]]\n",
        "print(classifier.predict(X_marks))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7OZuZVEmXfb",
        "outputId": "23a88d6d-a516-44b1-de72-066d69785c86"
      },
      "source": [
        "#ml linear regression\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "height=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "weight=[  8, 10 , 12, 14, 16, 18, 20]\n",
        "reg=linear_model.LinearRegression()\n",
        "reg.fit(height,weight)\n",
        "X_height=[[12.0]]\n",
        "print(reg.predict(X_height))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE3_-tYxmiOE",
        "outputId": "3477eb47-319a-4911-98c6-4c92f27ea47c"
      },
      "source": [
        "#dl linear regression\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "x = [[4],[5],[6],[7],[8],[9],[10]]\n",
        "y = [8, 10 , 12, 14, 16, 18, 20]\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, input_dim=1, activation= \"relu\"))\n",
        "model.add(Dense(1000, activation= \"relu\"))\n",
        "model.add(Dense(50, activation= \"relu\"))\n",
        "model.add(Dense(1))\n",
        "#model.summary() #Print model Summarymodel.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.fit(x,y,epochs=200)\n",
        "x=[[12.0]]\n",
        "print(model.predict(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 207.5196 - mean_squared_error: 207.5196\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 146.5755 - mean_squared_error: 146.5755\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 98.5235 - mean_squared_error: 98.5235\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 56.3669 - mean_squared_error: 56.3669\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 23.7187 - mean_squared_error: 23.7187\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.1020 - mean_squared_error: 4.1020\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9085 - mean_squared_error: 0.9085\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12.9137 - mean_squared_error: 12.9137\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 27.3837 - mean_squared_error: 27.3837\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 32.1771 - mean_squared_error: 32.1771\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 26.9792 - mean_squared_error: 26.9792\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 17.0880 - mean_squared_error: 17.0880\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.7466 - mean_squared_error: 7.7466\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.8657 - mean_squared_error: 1.8657\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.2282 - mean_squared_error: 1.2282\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9223 - mean_squared_error: 3.9223\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.6877 - mean_squared_error: 6.6877\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6280 - mean_squared_error: 8.6280\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.3078 - mean_squared_error: 9.3078\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.7291 - mean_squared_error: 8.7291\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.1579 - mean_squared_error: 7.1579\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.0289 - mean_squared_error: 5.0289\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8485 - mean_squared_error: 2.8485\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0992 - mean_squared_error: 1.0992\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1369 - mean_squared_error: 0.1369\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0903 - mean_squared_error: 0.0903\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7974 - mean_squared_error: 0.7974\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8354 - mean_squared_error: 1.8354\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6584 - mean_squared_error: 2.6584\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.9295 - mean_squared_error: 2.9295\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5746 - mean_squared_error: 2.5746\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7832 - mean_squared_error: 1.7832\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9134 - mean_squared_error: 0.9134\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2670 - mean_squared_error: 0.2670\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1166 - mean_squared_error: 0.1166\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4506 - mean_squared_error: 0.4506\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.8066 - mean_squared_error: 0.8066\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0250 - mean_squared_error: 1.0250\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.0345 - mean_squared_error: 1.0345\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8529 - mean_squared_error: 0.8529\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5616 - mean_squared_error: 0.5616\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2677 - mean_squared_error: 0.2677\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0648 - mean_squared_error: 0.0648\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0663 - mean_squared_error: 0.0663\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1982 - mean_squared_error: 0.1982\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3227 - mean_squared_error: 0.3227\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3807 - mean_squared_error: 0.3807\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.3506 - mean_squared_error: 0.3506\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2530 - mean_squared_error: 0.2530\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1340 - mean_squared_error: 0.1340\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0408 - mean_squared_error: 0.0408\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0173 - mean_squared_error: 0.0173\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0665 - mean_squared_error: 0.0665\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1187 - mean_squared_error: 0.1187\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1481 - mean_squared_error: 0.1481\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1435 - mean_squared_error: 0.1435\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1094 - mean_squared_error: 0.1094\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0624 - mean_squared_error: 0.0624\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0254 - mean_squared_error: 0.0254\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0478 - mean_squared_error: 0.0478\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0604 - mean_squared_error: 0.0604\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0576 - mean_squared_error: 0.0576\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0420 - mean_squared_error: 0.0420\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0219 - mean_squared_error: 0.0219\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2734e-04 - mean_squared_error: 7.2734e-04\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0049 - mean_squared_error: 0.0049\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0143 - mean_squared_error: 0.0143\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0228 - mean_squared_error: 0.0228\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0258 - mean_squared_error: 0.0258\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0223 - mean_squared_error: 0.0223\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0144 - mean_squared_error: 0.0144\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - mean_squared_error: 0.0063\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0044 - mean_squared_error: 0.0044\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0086 - mean_squared_error: 0.0086\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0111 - mean_squared_error: 0.0111\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0107 - mean_squared_error: 0.0107\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0077 - mean_squared_error: 0.0077\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0040 - mean_squared_error: 0.0040\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.0513e-04 - mean_squared_error: 7.0513e-04\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0038 - mean_squared_error: 0.0038\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_squared_error: 0.0039\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0023 - mean_squared_error: 0.0023\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0010 - mean_squared_error: 0.0010\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 6.4306e-04 - mean_squared_error: 6.4306e-04\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0026 - mean_squared_error: 0.0026\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0020 - mean_squared_error: 0.0020\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.4547e-04 - mean_squared_error: 7.4547e-04\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.2129e-04 - mean_squared_error: 6.2129e-04\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 8.7405e-04 - mean_squared_error: 8.7405e-04\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.2588e-04 - mean_squared_error: 8.2588e-04\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.1390e-04 - mean_squared_error: 6.1390e-04\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.0617e-04 - mean_squared_error: 6.0617e-04\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.5069e-04 - mean_squared_error: 7.5069e-04\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.1705e-04 - mean_squared_error: 9.1705e-04\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.8668e-04 - mean_squared_error: 9.8668e-04\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.2065e-04 - mean_squared_error: 9.2065e-04\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 7.6875e-04 - mean_squared_error: 7.6875e-04\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.2447e-04 - mean_squared_error: 6.2447e-04\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.6095e-04 - mean_squared_error: 5.6095e-04\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.9086e-04 - mean_squared_error: 5.9086e-04\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.6898e-04 - mean_squared_error: 6.6898e-04\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.2996e-04 - mean_squared_error: 7.2996e-04\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.3117e-04 - mean_squared_error: 7.3117e-04\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.7479e-04 - mean_squared_error: 6.7479e-04\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.9839e-04 - mean_squared_error: 5.9839e-04\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.4569e-04 - mean_squared_error: 5.4569e-04\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.3855e-04 - mean_squared_error: 5.3855e-04\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.6708e-04 - mean_squared_error: 5.6708e-04\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.0127e-04 - mean_squared_error: 6.0127e-04\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.1344e-04 - mean_squared_error: 6.1344e-04\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.9484e-04 - mean_squared_error: 5.9484e-04\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.5813e-04 - mean_squared_error: 5.5813e-04\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.2534e-04 - mean_squared_error: 5.2534e-04\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.1242e-04 - mean_squared_error: 5.1242e-04\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.1984e-04 - mean_squared_error: 5.1984e-04\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.3538e-04 - mean_squared_error: 5.3538e-04\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.4376e-04 - mean_squared_error: 5.4376e-04\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 5.3752e-04 - mean_squared_error: 5.3752e-04\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.1983e-04 - mean_squared_error: 5.1983e-04\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 5.0105e-04 - mean_squared_error: 5.0105e-04\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.9053e-04 - mean_squared_error: 4.9053e-04\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.9050e-04 - mean_squared_error: 4.9050e-04\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.9620e-04 - mean_squared_error: 4.9620e-04\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.9987e-04 - mean_squared_error: 4.9987e-04\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.9672e-04 - mean_squared_error: 4.9672e-04\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.8738e-04 - mean_squared_error: 4.8738e-04\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.7645e-04 - mean_squared_error: 4.7645e-04\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.6901e-04 - mean_squared_error: 4.6901e-04\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.6683e-04 - mean_squared_error: 4.6683e-04\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.6787e-04 - mean_squared_error: 4.6787e-04\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.6846e-04 - mean_squared_error: 4.6846e-04\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.6577e-04 - mean_squared_error: 4.6577e-04\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.5988e-04 - mean_squared_error: 4.5988e-04\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.5305e-04 - mean_squared_error: 4.5305e-04\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 4.4774e-04 - mean_squared_error: 4.4774e-04\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.4505e-04 - mean_squared_error: 4.4505e-04\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 4.4408e-04 - mean_squared_error: 4.4408e-04\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.4287e-04 - mean_squared_error: 4.4287e-04\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.4011e-04 - mean_squared_error: 4.4011e-04\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.3576e-04 - mean_squared_error: 4.3576e-04\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.3092e-04 - mean_squared_error: 4.3092e-04\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.2691e-04 - mean_squared_error: 4.2691e-04\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.2416e-04 - mean_squared_error: 4.2416e-04\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.2229e-04 - mean_squared_error: 4.2229e-04\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.2017e-04 - mean_squared_error: 4.2017e-04\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 4.1733e-04 - mean_squared_error: 4.1733e-04\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.1369e-04 - mean_squared_error: 4.1369e-04\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0992e-04 - mean_squared_error: 4.0992e-04\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.0657e-04 - mean_squared_error: 4.0657e-04\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.0392e-04 - mean_squared_error: 4.0392e-04\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 4.0156e-04 - mean_squared_error: 4.0156e-04\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.9913e-04 - mean_squared_error: 3.9913e-04\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.9624e-04 - mean_squared_error: 3.9624e-04\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.9304e-04 - mean_squared_error: 3.9304e-04\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8978e-04 - mean_squared_error: 3.8978e-04\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8683e-04 - mean_squared_error: 3.8683e-04\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8419e-04 - mean_squared_error: 3.8419e-04\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8169e-04 - mean_squared_error: 3.8169e-04\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7908e-04 - mean_squared_error: 3.7908e-04\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.7627e-04 - mean_squared_error: 3.7627e-04\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7330e-04 - mean_squared_error: 3.7330e-04\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7039e-04 - mean_squared_error: 3.7039e-04\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.6765e-04 - mean_squared_error: 3.6765e-04\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.6503e-04 - mean_squared_error: 3.6503e-04\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6248e-04 - mean_squared_error: 3.6248e-04\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5985e-04 - mean_squared_error: 3.5985e-04\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.5713e-04 - mean_squared_error: 3.5713e-04\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.5434e-04 - mean_squared_error: 3.5434e-04\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.5165e-04 - mean_squared_error: 3.5165e-04\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.4899e-04 - mean_squared_error: 3.4899e-04\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.4645e-04 - mean_squared_error: 3.4645e-04\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.4389e-04 - mean_squared_error: 3.4389e-04\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.4127e-04 - mean_squared_error: 3.4127e-04\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3865e-04 - mean_squared_error: 3.3865e-04\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.3603e-04 - mean_squared_error: 3.3603e-04\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3345e-04 - mean_squared_error: 3.3345e-04\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3092e-04 - mean_squared_error: 3.3092e-04\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.2842e-04 - mean_squared_error: 3.2842e-04\n",
            "[[23.961924]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHCEz7Hd4Hoj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "9wld0V1_4H-P",
        "outputId": "7f3eb0f9-5405-45c2-9bc9-5683050002a8"
      },
      "source": [
        "import socket\n",
        "#s//server scocket\n",
        "s=socket.socket()\n",
        "#tcp\n",
        "print(\"Socket created\")\n",
        "#make server socket\n",
        "#to bind port number\n",
        "\n",
        "s.bind(('localhost',9999))\n",
        "#ip adress ,port number\n",
        "s.listen(1)\n",
        "print('waiting for connections')\n",
        "#while loop \n",
        "\n",
        "while True:\n",
        "    c,addr=s.accept()\n",
        "    #gives client socket and returns the address of client\n",
        "    print(\"Connected with\",addr)\n",
        "    c.send(bytes(\"Welcome to DSU\",'utf-8'))\n",
        "    c.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Socket created\n",
            "waiting for connections\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c035fd986bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#gives client socket and returns the address of client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connected with\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36maccept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mIP\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maddress\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhostaddr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;31m# Issue #7995: if no default timeout is set and the listening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDvXU0-R4IEA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJO2-94L4IG2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5EiFjo_4IJv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "DcehFXoSmtsG",
        "outputId": "e85a178b-c83b-499e-90ff-35351093b14b"
      },
      "source": [
        "#dl in logistic regression or classification\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical \n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=1))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(X,y, epochs=100)\n",
        "X_marks=[[20]]\n",
        "print(model.predict(X_marks))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5c9c2345aa5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLp1DNKnUeC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}