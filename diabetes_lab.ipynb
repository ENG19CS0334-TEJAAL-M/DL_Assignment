{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diabetes_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUIOcGkge5rnDkw+IGigF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ENG19CS0334-TEJAAL-M/DL_Assignment/blob/main/diabetes_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0YjPUx-rwZk"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def _init_(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Weight inputs, add bias, then use the activation function\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    print(total)\n",
        "    return sigmoid(total)\n",
        "\n",
        "    weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "    bias = 4                   # b = 4\n",
        "    n = Neuron (weights, bias)\n",
        "    x = np.array([2, 3]) \n",
        "    print(n.feedforward(x))\n",
        "    # x1 = 2, x2 = 3 # 0.9990889488055994"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJN8wYePryD6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def _init_(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Weight inputs, add bias, then use the activation function\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    print(total)\n",
        "    return sigmoid(total)\n",
        "\n",
        "    weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "    bias = 4                   # b = 4\n",
        "    n = Neuron (weights, bias)\n",
        "    x = np.array([2, 3]) \n",
        "    print(n.feedforward(x))\n",
        "    # x1 = 2, x2 = 3 # 0.9990889488055994"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEuClp_8sH1e",
        "outputId": "bce628b8-a00b-4c44-e734-584cbce9a607"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Weight inputs, add bias, then use the activation function\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    print(total)\n",
        "    return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "bias = 4                   # b = 4\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
        "print(n.feedforward(x))    # 0.9990889488055994"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "0.9990889488055994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pURhrS_X56Cd"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "print(data)\n",
        "x = data.drop(\"Outcome\", axis=1)\n",
        "y = data[\"Outcome\"]\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(x,y, epochs=150, batch_size=10)\n",
        "_, accuracy = model.evaluate(x, y)\n",
        "print(\"Model accuracy: %.2f\"% (accuracy*100))\n",
        "predictions = model.predict(x)\n",
        "print([round(x[0]) for x in predictions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV9XUJUGnHRM"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "print(data)\n",
        "x = data.drop(\"Outcome\", axis=1)\n",
        "y = data[\"Outcome\"]\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\"))\n",
        "model.add(Dense(12, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n",
        "model.fit(x,y, epochs=150, batch_size=10)\n",
        "_, accuracy = model.evaluate(x, y)\n",
        "print(\"Model accuracy: %.2f\"% (accuracy*100))\n",
        "predictions = model.predict(x)\n",
        "print([round(x[0]) for x in predictions])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-fXnrje5lUa"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ19sWAmfOV1"
      },
      "source": [
        "class dog:\n",
        "    name = \"\"\n",
        "    age = 0\n",
        "\n",
        "    def bark(self):\n",
        "        print('Bark')\n",
        "obj1 = dog()\n",
        "obj1.name = \"Woof\"\n",
        "obj1.age = 5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnMgKTzypyAg"
      },
      "source": [
        "class dog:\n",
        "    name = \"\"\n",
        "    age = 0\n",
        "\n",
        "    def bark(self):\n",
        "        print('Bark')\n",
        "obj1 = dog()\n",
        "obj1.name = \"Woof\"\n",
        "obj1.age = 5\n",
        "print(obj1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-gjAQmvp-rM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}