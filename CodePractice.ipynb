{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodePractice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7U034KSeM/U9VL6WpYCfm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ENG19CS0334-TEJAAL-M/DL_Assignment/blob/main/CodePractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#practice codes"
      ],
      "metadata": {
        "id": "LFQbAJxUAeMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##class inheritance,basic python"
      ],
      "metadata": {
        "id": "dneqkrZ9oyqh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bgmTcvlAdZg",
        "outputId": "1d536c92-79d8-485c-f0b7-14d91443d5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "override\n",
            "tej tej tej \n",
            "no\n",
            "yes\n"
          ]
        }
      ],
      "source": [
        "class mom:\n",
        "  def silent(self):\n",
        "    print(\"yes\")\n",
        "class child(mom):\n",
        "  def naughty(self):\n",
        "    \n",
        "    print(\"no\")\n",
        "    super().silent()\n",
        "  def silent(self):\n",
        "    print(\"override\")\n",
        "    print(\"tej \"*3)\n",
        "obj=child()\n",
        "obj.silent()\n",
        "obj.naughty()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#logistic regression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X,y)\n",
        "X_marks=[[20]]\n",
        "print(classifier.predict(X_marks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5lUaet1pXSr",
        "outputId": "9c1da6eb-775f-49ef-b669-fe6f10ac234d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dnn classification\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=1))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(X,y, epochs=100)\n",
        "X_marks=[[20]]\n",
        "print(model.predict(X_marks))"
      ],
      "metadata": {
        "id": "rC3jS3weyEMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#linear regression\n",
        "\n",
        "from sklearn import linear_model\n",
        "height=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
        "weight=[  8, 10 , 12, 14, 16, 18, 20]\n",
        "reg=linear_model.LinearRegression()\n",
        "reg.fit(height,weight)\n",
        "X_height=[[12.0]]\n",
        "print(reg.predict(X_height))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSB4pETyyRJe",
        "outputId": "c43b82e0-25e5-4098-f53d-582245b6c6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dnn linear regresiion\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "x = [[4],[5],[6],[7],[8],[9],[10]]\n",
        "y = [8, 10 , 12, 14, 16, 18, 20]\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, input_dim=1, activation= \"relu\"))\n",
        "model.add(Dense(1000, activation= \"relu\"))\n",
        "model.add(Dense(50, activation= \"relu\"))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\n",
        "model.fit(x,y,epochs=200)\n",
        "x=[[12.0]]\n",
        "print(model.predict(x))"
      ],
      "metadata": {
        "id": "CT8mZ_uMyZbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#neural network\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class Neuron:\n",
        "  def __init__(self, weights, bias):\n",
        "    self.weights = weights\n",
        "    self.bias = bias\n",
        "\n",
        "  def feedforward(self, inputs):\n",
        "    # Weight inputs, add bias, then use the activation function\n",
        "    total = np.dot(self.weights, inputs) + self.bias\n",
        "    print(total)\n",
        "    return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
        "bias = 4                   # b = 4\n",
        "n = Neuron(weights, bias)\n",
        "\n",
        "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
        "print(n.feedforward(x))    # 0.9990889488055994"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VkBKCmpypOP",
        "outputId": "9248e17f-23c1-4ecc-dd8b-f34788b52d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "0.9990889488055994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#naive based\n",
        "#06/09/21\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df = pd.read_csv(\"Naive-Bayes-Classifier-Data.csv\")\n",
        "print(df)\n",
        "df.head()\n",
        "x=df.drop('diabetes',axis=1)\n",
        "y=df['diabetes']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "model=GaussianNB()\n",
        "model.fit(x_train,y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "powt_duGyrJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n0uw5Kzg1Mdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cnn"
      ],
      "metadata": {
        "id": "Fw1uOGGl1MvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow numpy mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UHHhagk1Kx0",
        "outputId": "7d4397ff-8575-4f83-ad6f-8fc0b9ae881f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.0)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The full CNN code!\n",
        "####################\n",
        "\n",
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n",
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Compile the model.\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train the model.\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")\n",
        "\n",
        "# Save the model to disk.\n",
        "model.save_weights('cnn.h5')\n",
        "\n",
        "# Load the model from disk later using:\n",
        "# model.load_weights('cnn.h5')\n",
        "\n",
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YWx8Y_W1Crt",
        "outputId": "1b52df1e-a53f-479b-aa4c-4bca791de931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 28s 15ms/step - loss: 0.3428 - accuracy: 0.9014 - val_loss: 0.1846 - val_accuracy: 0.9472\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.1587 - accuracy: 0.9548 - val_loss: 0.1223 - val_accuracy: 0.9641\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 25s 14ms/step - loss: 0.1172 - accuracy: 0.9664 - val_loss: 0.1045 - val_accuracy: 0.9662\n",
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11 lines of code cnn"
      ],
      "metadata": {
        "id": "HBxYNPqY28z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "# number of output channels \n",
        "#5×5 moving window, followed by the strides in the x and y directions (1, 1)\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "#size of the pooling in the x and y directions – (2, 2) \n",
        "\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# we specify 1000 nodes, each activated by a ReLU function.  \n",
        "#Tsoft-max classification, or output layer, which is the size of the number of our classes\n",
        "#(batch_size, 28, 28,  32) – the 28 x 28 is the size of the image, and the 32 is the number of output channels from the previous layer. \n",
        "# However, notice we don’t have to explicitly detail what the shape of the input is – Keras will work it out for us.  \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[history])\n",
        "\n",
        "# The verbose flag pecifies if you want detailed information being printed in the console about the progress of the training.  \n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "tqxLRjEn2tQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "#0 means fail and 1 means pass\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "from sklearn.neighbors import KNeighborsClassifier  \n",
        "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
        "classifier.fit(X,y) \n",
        "X_marks=[[50]]\n",
        "print(classifier.predict(X_marks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWYLRFgk1DHd",
        "outputId": "d1df6ec1-a040-4267-d9cc-0cfec82f65ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DECISION TREE\n",
        "#0 means fail and 1 means pass\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "RandomForestRegModel = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "RandomForestRegModel.fit(X,y)\n",
        "X_marks=[[20]]\n",
        "print(RandomForestRegModel.predict(X_marks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59PlJqJh1a0P",
        "outputId": "416be462-0d4a-48db-9f86-a34f2ea4c574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FOREST\n",
        "#0 means fail and 1 means pass\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "RandomForestRegModel = RandomForestRegressor()\n",
        "RandomForestRegModel.fit(X,y)\n",
        "classifier.fit(X,y)\n",
        "X_marks=[[70]]\n",
        "print(RandomForestRegModel.predict(X_marks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1BSDmiI1c6c",
        "outputId": "2e08b05f-84c3-47f3-82df-cfa68de8f766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM SUPPORT VECTOR MACHINE\n",
        "#0 means fail and 1 means pass\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
        "y = [0,1,1,1,0,0,1]\n",
        "classifier = SVC(kernel = 'linear', random_state = 0)\n",
        "classifier.fit(X,y)\n",
        "X_marks=[[55]]\n",
        "print(classifier.predict(X_marks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcd2KLKK1esB",
        "outputId": "deac8fc6-a5e7-4490-e74b-662702c3297f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QmVaWMMq1gQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using functional api"
      ],
      "metadata": {
        "id": "vqIFf73g6u8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Import the libraries\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input,Dense\n",
        "## Creating the layers\n",
        "input_layer = Input(shape=(3,))\n",
        "Layer_1 = Dense(4, activation=\"relu\")(input_layer)\n",
        "Layer_2 = Dense(4, activation=\"relu\")(Layer_1)\n",
        "output_layer= Dense(1, activation=\"linear\")(Layer_2)\n",
        "\n",
        "\n",
        "##Defining the model by specifying the input and output layers\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "## defining the optimiser and loss function\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse')\n",
        "## training the model\n",
        "model.fit(X_train, y_train,epochs=400, batch_size=128,validation_data=(X_test,y_test))\n"
      ],
      "metadata": {
        "id": "csFhh4zp6zi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using sequential api"
      ],
      "metadata": {
        "id": "nLLTpAv861fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Import the libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "## Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(4,activation='relu')) ##<----- You don't have to specify input size.Just define the hidden layers \n",
        "model.add(Dense(4,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "\n",
        "## defining the optimiser and loss function\n",
        "model.compile(optimizer='adam',loss='mse')\n",
        "## training the model\n",
        "model.fit(x=X_train,y=y_train,\n",
        "          validation_data=(X_test,y_test),\n",
        "          batch_size=128,epochs=400)"
      ],
      "metadata": {
        "id": "r-UGS4V3639q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cPBo6ZCO74H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-deep-learning-optimizers/\n",
        "\n",
        "ml -algorithms,\n",
        "\n",
        "ip ,op layer and weights deep learning\n",
        "\n",
        "labels and features in ml\n",
        "\n",
        "forward and backward propagationn +weights in dl is advantageous\n",
        "\n",
        "can add hidden layers in dnn to increase the accuracy.\n",
        "\n",
        "gradiecent is used in ml to minimize the error and in dl we use backpropagation\n",
        "\n",
        "to build the model model we use functional and sequential api in dnn\n",
        "\n",
        "and in ml we use algorithms like logistic regression,linear ,knn,random forest,svm,decision tree\n",
        "\n",
        "Supervised Learning, Unsupervised Learning and Reinforcement Learning\n",
        "Convolutional Neural Networks, Recurrent Neural Networks,generative adversial neural network"
      ],
      "metadata": {
        "id": "4oJAWp5L74aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4FJjxe2f74KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F6zG6naf74NZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}